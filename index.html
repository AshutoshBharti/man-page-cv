<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>ashutosh - sre - data engineering - devops - Resume</title>
  <link href="css/style.css" media="screen" rel="stylesheet" type="text/css">
</head>
<body>

<pre class="manheader">ASHUTOSH KUMAR                 User's Resume Manpage                 <a href="mailto: aashu.outofbox@gmail.com">mail: aashu.outofbox@gmail.com</a></pre>

<h1>NAME</h1>
<p class="subtext">
  Ashutosh Kumar - Decade long experience in SRE & Devops. Data Engineering Pro for over 3 years.
</p>

<h1>Work Quotes</h1>
<p class="subtext">
  The lesser you are needed by developers, the better you are doing as an SRE/Devops<br>
  Its not just amount of data you handle, its also how well you guard it.
</p>

<h1>SYNOPSIS</h1>
<p class="subtext">
 <a href="#option9">[--consultant-lead-site-reliability-engineer]</a> <a href="#option8">[--consultant-site-reliability-engineer]</a>  <a href="#option1">[--site-reliability-engineer-and-lead]</a>  <a href="#option2">[--devops-engineer]</a> <a href="#option3">[--network-engineer]</a>
</p>

<h1>SEE</h1>
<p class="subtext">
<a href="#option4">[SKILLS]</a> <a href="#option5">[HISTORY]</a> <a href="#option6">[EDUCATION]</a> <a href="#option7">[CONTACT]</a>
</p>

<h1>STORY SO FAR (if you don't want to read complete resume just read this)</h1>
<p class="subtext">
Started career as a Network engineer (ECE graduate) at Orange Business Services, worked on monitoring its backbone and troubleshooting related issues. It is here, where I developed the understanding of networks, ip, subnets and NMS softwares.</p>

<p class="subtext">
Joined Helpshift, as a Systems Engineer, started with running basic linux commands, creating users, cleaning disk spaces. Moved onto automating sysadmin tasks and then Devops. I learnt, tried, broke, worked and reworked tasks involving the below mentioned tech stacks. <a href="#option4">[SKILLS]</a>. By the time I left, I was owner of monitoring (sensu + graphite), CICD, Kafka(on ec2) and Postgres(on ec2) at Helpshift.
</p>

<p class="subtext">
Moved to Hungerbox as an SRE Lead Consultant managing a small team of 2 people (including me). I was hired to facilitate the movement of infra from one account to another and prepare for the daily order scale up from 40K to 4L. Wrote tons of terraform, boto3 and ansible to port the infra to IaC</a>.
</p>

<p class="subtext">
My next role as a Consultant SRE at Ocrolus Inc, Gurugram, is a story that unfloded mainly because of my love for data-science, data-analytics and streaming services (Kafka, Debezium, spark, Tableau, snowflake). Things that I have done great at so far are, implementing debezium for bringing data from AWS RDS to AWS MSK, bring down full data-sync (3TB) time from RDS to MSK to 6h (from 14h), moving development teams to use <a href="https://garden.io/">'garden'</a> for them to have the same code deployed and tested remotely without the hassle of maintaining local docker and k8s. Introducing access restrictions that prevents US data being visible to non-US employees and vice-versa.
</p>

<p class="subtext">
Searching for a role in AI systems domain, I finally landed Consultant SRE job at at Mightybot.ai. It was a role fully of GCP where I created Infra revolving around Kubernetes from scratch. It was my first dealing with vector databases and GCP. I handled everything from GC architecture to Github Actions based CI/CD.
</p>
<p class="subtext">
  Highlights:
</p>
<ul class="subtext">
  <li> <b>AWS</b>: infra that sees a scale of millions of events per second, used by Banks;</li>
  <li> <b>Azure</b>: replicating AWS infra in azure from the ground up;</li>
  <li> <b>GCP</b>: complete infra and CI/CD using Github actions for a AI company</li>
  <li> <b>K8s</b>: porting services from ec2 to k8s using EKS, ECS, helm; GKE based API layer from scratch for AI driven global webapp</li>
  <li> <b>IaC</b>: moving the infra to from no code (all manual) to infrastructure;</li>
  <li> <b>Scale</b>: handling traffic growing from 11K rps to 200K rps;</li>
  <li> <b>Monitoring</b>: centralised monitoring for infra of 5 accounts and 2 cloud providers;</li>
  <li> <b>Automations</b>: custom monitoring scripts, tools for auto alert's remediations;</li>
  <li> <b>CI/CD</b>: designing, writing, deploying complete CI/CD infra, spans across AWS, Azure, GCP; Pro with Azure Devops, Jenkins, Github and Gitlab </li>
  <li> <b>Upgrades</b>: carrying out upgrades (no downtime): PG, Mongo, MySQL, Kafka, Zookeeper;</li>
  <li> <b>Enabler</b>: reducing dependency of developers on devops/sre (25 to 4 weekly tickets);</li>
  <li> <b>Bookkeeper</b>: established a culture of documentation, processes, audits and RCAs;</li>
  <li> <b>Cautious</b>: taking care of security audit needs for the company;</li>
  <li> <b>Moneyminded</b>: moving to serverless as/where possible, optimizations to contain costs</li>
</ul>

<h1 id="option4">SKILLS</h1>
<p class="subtext">
 <table class="subtext" style="width:50%">
  <tr>
    <td>Ansible</td>
    <td>Terraform</td>
    <td>boto/boto3/moto</td>
    <td>Azure-Python-SDK</td>
  </tr>
  <tr>
    <td>Bash, Python</td>
    <td>Groovy</td>
    <td>Ruby</td>
    <td>Go</td>
  </tr>
  <tr>
    <td>EFK Stack</td>
    <td>Vagrant, Docker</td>
    <td>Kubernetes, EKS</td>
    <td>Atlassian Stack</td>
  </tr>
  <tr>
    <td>Git, Gitlab, Github, Azure Devops</td>
    <td>Packer, Teamcity</td>
    <td>Jenkins, Rundeck</td>
    <td>Sonarqube</td>
  </tr>
  <tr>
    <td>Newrelic</td>
    <td>Prometheus, VictoriaMetrics</td>
    <td>Sensu</td>
    <td>Netdata</td>
  </tr>
  <tr>
    <td>TCP/IP/HTTP</td>
    <td>Nginx</td>
    <td>HAProxy</td>
    <td>Debugging/RCA/Audits</td>
  </tr>
  <tr>
    <td>Kafka, Zookeeper, Storm</td>
    <td>Mongo, MySQL, PostgreSQL</td>
    <td>Snowflake, Tableau, Spark</td>
    <td>ProxySQL</td>
  </tr>
</table>
</p>

<h1 id="option5">HISTORY</h1>
<p id="option9" class="subtext">
--consultant-lead-site-reliability-engineer <br>
   : <a href="https://www.mightybot.ai/">mightybot.ai, Remote</a><br>
</p>
<ul class="doublesubtext">
  <li> SRE and Devops Consultant for mightybot.ai </li>
    <ul>
      <li> Designed and created GCP infra for multi browser based AI Chat plugin with APIs on GKE. <br> At peak, the servers handle over 50k+ chats simultaneously </li>
      <li> Complete CI/CD using Github Actions </li>
    </ul>
</ul>
<p id="option8" class="subtext">
--consultant-site-reliability-engineer (and lead)<br>
   : <a href="https://www.ocrolus.com/">Ocrolus Inc, Remote </a><br>
</p>
<ul class="doublesubtext">
  <li> SRE for Ocrolus Engineering and Data-platform </li>
    <ul>
      <li> Designed pipeline for bringing data from AWS RDS to AWS MSK. Currently the pipeline supports over 40 applications. <br> It can sync over 8TB data from various sources to Kafka in 6hrs</li>
      <li> Complete CI/CD for dataplatform applications</li>
      <li> Hiding PII data of US clients from non US employees with row level security in RDS (postgreSQl) and topic level security in kafka </li>
    </ul>
</ul>
<p id="option1" class="subtext">
--consultant-site-reliability-engineer-and-lead <br>
   : <a href="https://www.hungerbox.com/">Hungerbox, Bangalore</a><br>
</p>
<ul class="doublesubtext">
  <li> Working in a team of 3, moved entire AWS infra to a new account in one and half months: Terraform, Cloudformation, Ansible and manual</li>
  <li> CI/CD pipeline: Git (local) + Gitlab + Jenkins (with docker slaves in ECS) + AWS Systems Manager </li>
  <li> Integrated CI/CD pipeline with Gatling for applications performance testing during the development </li>
  <li> Wrote Custom app (django) which provides UI for crons monitoring, deployment and alerts </li>
  <li> Created/Maintaining Docker environments of Application Servers for developers, used in local development </li>
  <li> Put in processes for Access Control, Change Management, adopted Confluence for Documentation </li>
  <li> Optimized costs to keep it constant while the infra grew by 40 percent </li>
  <li> Executed Pentest of Network and Application with Security Audit providers, resolved all the findings in a month, Rescan passed </li>
</ul>

<p id="option2" class="subtext">
--devops-engineer <br>
   : <a href="https://www.helpshift.com/">Helpshift, Pune</a><br>
   : Mar 2015 - Oct 2019
</p>
<ul class="doublesubtext">
  <li> Working on AWS and Azure:  EC2, CloudFront, S3, Route 53, VPC, Cloudwatch etc (equivalent services in Azure)
    <ul>
      <li> Boto, AWS Ruby SDK, Azure Python SDK, Ansible for automating the workflows and management </li>
      <li> Planned and executed the move of ec2 infra of 500+ servers from classic to VPC with zero downtime</li>
      <li> Replicated the aws infra in azure using equivalent services of the latter</li></ul>
    <li> Improved the monitoring infra (Sensu, Grafana, RabbitMQ, Burrow, Cloudwatch) </li>
      <ul>
        <li> Integrated VictorOps in infra, eliminating night shifts for engineers for monitoring </li>
        <li> Using Python Flask, developed a web application integrated with ’slack’  and g-calendar which returns the details of current oncall for a team </li>
        <li> Integrated Burrow for kafka monitoring. Enhanced Burrow to have in memory state for kafka consumers </li>
      </ul>
  <li> Automated provisioning of Production, Staging, Dev infra using Ansible, terraform
      <ul>
        <li> Using groovy, wrote a jenkins job to spawn multi node sandbox in staging infra, enabling developers to not depend on Ops for it </li>
      </ul>
  <li> Designed Centralized Logging (Elasticsearch, Fluentd, Kibana EFK) at helpshift which roughly gets traffic of about 100Mb/s
        <ul>
          <li> Added auditbeat to logging infra which logs user activity and processes and pushes it to EFK </li>
        </ul>
  <li> Designed and the deployed the Sonarqube infra which sits behind a proxy with Google auth enabled and custom plugins
        <ul>
          <li> Wrote custom plugin for Objective C analysis using OCLint, cobertura, gcovr and lizard </li>
        </ul>
</ul>


<p id="option3" class="subtext">
--network-engineer <br>
   : <a href="https://www.orange-business.com/en">Orange Business Services, Gurgaon</a><br>
   : Jul 2014 - Mar 2015
</p>
<ul class="doublesubtext">
  <li> Worked on monitoring Orange Backbone Network using their proprietary tools </li>
  <li> Developed understanding of subnets, CIDRs, Ips, NMS softwares </li>
</ul>

<h1 id="option6">EDUCATION</h1>
<p class="subtext bottomcut">
  * Bachelor of Technology - LNMIIT, Jaipur - 2014;<br>
</p>
<p class="subtext bottomcut">
  * Higher Secondary - Fergusson College, Pune - 2009;<br>
</p>
<p class="subtext bottomcut">
  * Senior Secondary - DAV Public School, Gaya - 2007<br>
</p>
<br>

<h1 id="option7">CONTACT</h1>
<ul class="subtext">
  <li> E-mail:      aashu dot outofbox at gmail dot com </li>
  <li> Phone:       (91) 83404 12 810</li>
</ul>
<p></p>

<br><br>
<pre class="manheader">Ashutosh Kumar                          2021-04-01                                 ASHUTOSH
</pre>

<p class="footer">
  © Ashutosh Kumar [+91-8340-412-810] [aashu.outofbox@gmail.com] [animal lover] [accepts pay as Beer and Biryani]
</p>

</body>
</html>
